							Craig Milo Rogers
							24-Mar-2016

	This folder contains sample JSON data for use in testing the interface
to CRF++.  It contains data that has been scraped from Web sites, tokenized,
and annotated for hair and eye color.  A single record may contain multiple
English sentences.  These files do not contain "features" as produced by
crf_features.

	The text in these files may include Unicode codes, encoded using
UTF-8.  HTML entities (e.g., "<u>", "<br>") may appear in the text fields of
these examples, and are converted to HTML escapes for when tokenized (e.g.,
"&lt;br&gt;" and "&lt;u&gt;".

Structure
=========

[	The outermost container is a sequence, representing a sequence of
	individual data sources.

  {	The next container is a map from properties to values:

     "text": "..."
	The text of each record.		

     "allTokens": [ ... ]
	Tokenized text.

     "annotationSet": { "eyeColor": [ { ... } ... ], "hairType": [ { ... }
     ... ] }
	Annotations for eye color and hair type.

     "uri": "xxx"
        An identifier for the source of the record.

Format
======

	The data samples originally arrived in JSON format.  All samples in a files
were enclosed in an outer array (per the Structure notes, above), and the data was
pretty printed (printed with line breaks and indentation).  

http://json.org/

	Pedro specified that the input and output should be keyed JSON Lines.
The key will be a URI.  A "keyed JSON line" is a key, followed by <tab>,
followed by a JSON line.  For more on JSON Lines, see:

http://jsonlines.org/


Files
=====

1)	sample1.json

	This file is a short example of the expected data format, with human
	annotations for eye color and hair color.

2)	adjudicated_modeled_live_eyehair_100_03.json

	This file contains contains a larger sample of input data with
	human annotations for eye color and hair color.

3)	adjudicated_modeled_live_eyehair_100_03-001.json
	adjudicated_modeled_live_eyehair_100_03-002.json
	adjudicated_modeled_live_eyehair_100_03-003.json

	These files extract the first, second, and third data records
from the larger dataset.

4)	adjudicated_modeled_live_eyehair_100_03.jsonl

	This is the larger sample, converted in into (unkeyed) JSON Lines
format as follows:

jq -c -M '.[]' \
   < adjudicated_modeled_live_eyehair_100_03.json \
   > adjudicated_modeled_live_eyehair_100_03.jsonl

5)	Extracting the URI keys from the original dataset
	(note that the URIs are written as quoted strings):

jq -c -M '.[].uri' \
   < adjudicated_modeled_live_eyehair_100_03.json \
   > adjudicated_modeled_live_eyehair_100_03.uri

6)	Extracting the URI keys from the JSON Lines dataset (note
	that the '.[]' is gone) (note that the URIs are written as
	quoted strings):

jq -c -M '.uri' \
   < adjudicated_modeled_live_eyehair_100_03.jsonl \
   > adjudicated_modeled_live_eyehair_100_03.uri

7)	Using the Unix "paste" command, build a keyed JSON Lines file
	from the JSON Lines file and the URI file.  Should we use a
	special filename extension, such as ".kjsonl"?

paste adjudicated_modeled_live_eyehair_100_03.uri \
      adjudicated_modeled_live_eyehair_100_03.jsonl \
    > adjudicated_modeled_live_eyehair_100_03.kjsonl

8)	Using the Unix "paste" and "tr" commands, build a keyed JSON Lines
	from the JSON Lines file and the URI file.  Strip the double quotes
	from the URI key (assuming that the key does not contain internal
	double quotes of significance).

cat adjudicated_modeled_live_eyehair_100_03.uri \
| tr -d '"' \
| paste - adjudicated_modeled_live_eyehair_100_03.jsonl \
> adjudicated_modeled_live_eyehair_100_03.kjsonl
